import re

import scrapy


class QuotesSpider(scrapy.Spider):
    filename = 'rapid7_scrapy.csv'
    name = "quotes"
    URL = 'https://www.rapid7.com/db/?q=2016&type=nexpose'
    start_urls = [URL]

    def parse(self, response):
        data_dict = {}
        SET_SELECTOR = "section.vulndb__results"
        for cve_data in response.css(SET_SELECTOR):
            for i in range(len(cve_data.css("div.resultblock__info-title::text").getall())):
                cve_id = cve_data.css("div.resultblock__info-title::text").getall()[i]
                cve_id = clean_string(cve_id)
                cve_date = cve_data.css("div.resultblock__info-meta::text").getall()[i]
                cve_date = clean_string(cve_date)
                data_dict.update(cve_id=cve_id, rapid7_exploit_date=cve_date)
                print(data_dict)
            yield data_dict


        page_index = (int(response.css('li.active a::text').get()) + 1)
        next_page = 'https://www.rapid7.com/db/?q=2016&type=nexpose'+'&page='+ str(page_index)
        if next_page is not None and page_index < 3:
            next_page = response.urljoin(next_page)
            yield scrapy.Request(next_page, callback=self.parse)


def clean_string(str):
    str = re.sub(r"[\n\t\r'  ']+", "", str)
    return str
